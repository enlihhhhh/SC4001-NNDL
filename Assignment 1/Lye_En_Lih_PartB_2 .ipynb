{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFVxWZGJxprU"
   },
   "source": [
    "# CS4001/4042 Assignment 1, Part B, Q2\n",
    "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EycCozG06Duu"
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lq0elU0J53Yo"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import R2Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU3xdVpwzuLx"
   },
   "source": [
    ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_oYG6lNIh7Mp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (87370, 11)\n",
      "Testing Data: (72183, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "\n",
    "# Training Data\n",
    "df_train = df[df['year'] <= 2020].copy()\n",
    "# Testing Data\n",
    "df_test = df[df['year'] >= 2021].copy()\n",
    "\n",
    "# Dropping Unncessary Columns\n",
    "df_train.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "df_test.drop(columns=['year','full_address','nearest_stn'], inplace=True)\n",
    "\n",
    "print(\"Training Data:\", df_train.shape)\n",
    "print(\"Testing Data:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>town</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>406 ANG MO KIO AVENUE 10</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.007264</td>\n",
       "      <td>7.006044</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>2 ROOM, Improved</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>232000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>108 ANG MO KIO AVENUE 4</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.271389</td>\n",
       "      <td>7.983837</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>60.583333</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>602 ANG MO KIO AVENUE 5</td>\n",
       "      <td>Yio Chu Kang</td>\n",
       "      <td>1.069743</td>\n",
       "      <td>9.090700</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.416667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>262000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>465 ANG MO KIO AVENUE 10</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.946890</td>\n",
       "      <td>7.519889</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>68.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>601 ANG MO KIO AVENUE 5</td>\n",
       "      <td>Yio Chu Kang</td>\n",
       "      <td>1.092551</td>\n",
       "      <td>9.130489</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.416667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year        town              full_address   nearest_stn  \\\n",
       "0      1  2017  ANG MO KIO  406 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
       "1      1  2017  ANG MO KIO   108 ANG MO KIO AVENUE 4    Ang Mo Kio   \n",
       "2      1  2017  ANG MO KIO   602 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
       "3      1  2017  ANG MO KIO  465 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
       "4      1  2017  ANG MO KIO   601 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
       "\n",
       "   dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "0             1.007264       7.006044           0.016807   \n",
       "1             1.271389       7.983837           0.016807   \n",
       "2             1.069743       9.090700           0.016807   \n",
       "3             0.946890       7.519889           0.016807   \n",
       "4             1.092551       9.130489           0.016807   \n",
       "\n",
       "   eigenvector_centrality         flat_model_type  remaining_lease_years  \\\n",
       "0                0.006243        2 ROOM, Improved              61.333333   \n",
       "1                0.006243  3 ROOM, New Generation              60.583333   \n",
       "2                0.002459  3 ROOM, New Generation              62.416667   \n",
       "3                0.006243  3 ROOM, New Generation              62.083333   \n",
       "4                0.002459  3 ROOM, New Generation              62.416667   \n",
       "\n",
       "   floor_area_sqm storey_range  resale_price  \n",
       "0            44.0     10 TO 12      232000.0  \n",
       "1            67.0     01 TO 03      250000.0  \n",
       "2            67.0     01 TO 03      262000.0  \n",
       "3            68.0     04 TO 06      265000.0  \n",
       "4            67.0     01 TO 03      265000.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159553 entries, 0 to 159552\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   month                   159553 non-null  int64  \n",
      " 1   year                    159553 non-null  int64  \n",
      " 2   town                    159553 non-null  object \n",
      " 3   full_address            159553 non-null  object \n",
      " 4   nearest_stn             159553 non-null  object \n",
      " 5   dist_to_nearest_stn     159553 non-null  float64\n",
      " 6   dist_to_dhoby           159553 non-null  float64\n",
      " 7   degree_centrality       159553 non-null  float64\n",
      " 8   eigenvector_centrality  159553 non-null  float64\n",
      " 9   flat_model_type         159553 non-null  object \n",
      " 10  remaining_lease_years   159553 non-null  float64\n",
      " 11  floor_area_sqm          159553 non-null  float64\n",
      " 12  storey_range            159553 non-null  object \n",
      " 13  resale_price            159553 non-null  float64\n",
      "dtypes: float64(7), int64(2), object(5)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_q9PoR50JAA"
   },
   "source": [
    ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
    "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
    "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
    "features and the categorical features. Use this component to transform the training dataset.\n",
    "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 linear layers in the MLP, with 200 and 100 neurons respectively.\n",
    "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 100 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_embed_cols = [\n",
    "    ('month', len(np.unique(df['month']))),\n",
    "    ('town', len(np.unique(df['town']))),\n",
    "    ('flat_model_type', len(np.unique(df['flat_model_type']))),\n",
    "    ('storey_range', len(np.unique(df['storey_range']))),\n",
    "]\n",
    "\n",
    "\n",
    "continuous_cols = ['dist_to_nearest_stn','dist_to_dhoby','degree_centrality','eigenvector_centrality',\n",
    "                 'remaining_lease_years','floor_area_sqm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZBY1iqUXtYWn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env_pytorch/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:334: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "tab_preprocessor = TabPreprocessor(\n",
    "    cat_embed_cols = cat_embed_cols, continuous_cols = continuous_cols\n",
    ")\n",
    "\n",
    "# Scaled Training Data\n",
    "X_tab = tab_preprocessor.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the TabMlp Model\n",
    "model = TabMlp(tab_preprocessor.column_idx, \n",
    "                cat_embed_input = tab_preprocessor.cat_embed_input, \n",
    "                cat_embed_dropout = 0.1,\n",
    "                continuous_cols = continuous_cols,\n",
    "                mlp_hidden_dims = [200, 100])\n",
    "\n",
    "wide_deep = WideDeep(deeptabular = model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Trainer \n",
    "trainer = Trainer(model = wide_deep,\n",
    "                  objective = \"regression\",\n",
    "                  lr_scheduler_step = False,  \n",
    "                  num_workers = 0,  \n",
    "                  metrics = [R2Score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|███| 1366/1366 [00:07<00:00, 193.17it/s, loss=6.9e+10, metrics={'r2': -1.9059}]\n",
      "epoch 2: 100%|█████| 1366/1366 [00:07<00:00, 183.53it/s, loss=9.7e+9, metrics={'r2': 0.5917}]\n",
      "epoch 3: 100%|████| 1366/1366 [00:07<00:00, 188.26it/s, loss=6.57e+9, metrics={'r2': 0.7235}]\n",
      "epoch 4: 100%|█████| 1366/1366 [00:07<00:00, 184.54it/s, loss=5.6e+9, metrics={'r2': 0.7644}]\n",
      "epoch 5: 100%|████| 1366/1366 [00:08<00:00, 167.43it/s, loss=5.13e+9, metrics={'r2': 0.7843}]\n",
      "epoch 6: 100%|████| 1366/1366 [00:08<00:00, 158.64it/s, loss=4.84e+9, metrics={'r2': 0.7963}]\n",
      "epoch 7: 100%|████| 1366/1366 [00:10<00:00, 125.14it/s, loss=4.66e+9, metrics={'r2': 0.8041}]\n",
      "epoch 8: 100%|████| 1366/1366 [00:10<00:00, 135.84it/s, loss=4.46e+9, metrics={'r2': 0.8123}]\n",
      "epoch 9: 100%|████| 1366/1366 [00:09<00:00, 145.54it/s, loss=4.35e+9, metrics={'r2': 0.8169}]\n",
      "epoch 10: 100%|███| 1366/1366 [00:09<00:00, 147.67it/s, loss=4.34e+9, metrics={'r2': 0.8175}]\n",
      "epoch 11: 100%|███| 1366/1366 [00:09<00:00, 141.30it/s, loss=4.24e+9, metrics={'r2': 0.8218}]\n",
      "epoch 12: 100%|███| 1366/1366 [00:09<00:00, 146.13it/s, loss=4.19e+9, metrics={'r2': 0.8239}]\n",
      "epoch 13: 100%|███| 1366/1366 [00:09<00:00, 143.83it/s, loss=4.15e+9, metrics={'r2': 0.8254}]\n",
      "epoch 14: 100%|███| 1366/1366 [00:09<00:00, 142.30it/s, loss=4.08e+9, metrics={'r2': 0.8284}]\n",
      "epoch 15: 100%|███| 1366/1366 [00:09<00:00, 139.54it/s, loss=4.08e+9, metrics={'r2': 0.8283}]\n",
      "epoch 16: 100%|███| 1366/1366 [00:09<00:00, 137.01it/s, loss=4.05e+9, metrics={'r2': 0.8297}]\n",
      "epoch 17: 100%|██████| 1366/1366 [00:09<00:00, 142.48it/s, loss=4e+9, metrics={'r2': 0.8316}]\n",
      "epoch 18: 100%|███| 1366/1366 [00:09<00:00, 140.95it/s, loss=3.98e+9, metrics={'r2': 0.8323}]\n",
      "epoch 19: 100%|███| 1366/1366 [00:09<00:00, 138.40it/s, loss=3.95e+9, metrics={'r2': 0.8337}]\n",
      "epoch 20: 100%|███| 1366/1366 [00:09<00:00, 139.67it/s, loss=3.95e+9, metrics={'r2': 0.8337}]\n",
      "epoch 21: 100%|███| 1366/1366 [00:09<00:00, 141.78it/s, loss=3.91e+9, metrics={'r2': 0.8353}]\n",
      "epoch 22: 100%|███| 1366/1366 [00:09<00:00, 149.13it/s, loss=3.92e+9, metrics={'r2': 0.8351}]\n",
      "epoch 23: 100%|███| 1366/1366 [00:09<00:00, 147.75it/s, loss=3.92e+9, metrics={'r2': 0.8352}]\n",
      "epoch 24: 100%|███| 1366/1366 [00:09<00:00, 151.00it/s, loss=3.89e+9, metrics={'r2': 0.8364}]\n",
      "epoch 25: 100%|███| 1366/1366 [00:09<00:00, 144.74it/s, loss=3.88e+9, metrics={'r2': 0.8368}]\n",
      "epoch 26: 100%|███| 1366/1366 [00:09<00:00, 142.70it/s, loss=3.84e+9, metrics={'r2': 0.8383}]\n",
      "epoch 27: 100%|███| 1366/1366 [00:09<00:00, 145.31it/s, loss=3.88e+9, metrics={'r2': 0.8369}]\n",
      "epoch 28: 100%|███| 1366/1366 [00:09<00:00, 145.11it/s, loss=3.84e+9, metrics={'r2': 0.8384}]\n",
      "epoch 29: 100%|███| 1366/1366 [00:09<00:00, 149.01it/s, loss=3.82e+9, metrics={'r2': 0.8393}]\n",
      "epoch 30: 100%|███| 1366/1366 [00:09<00:00, 140.65it/s, loss=3.83e+9, metrics={'r2': 0.8388}]\n",
      "epoch 31: 100%|████| 1366/1366 [00:09<00:00, 144.62it/s, loss=3.8e+9, metrics={'r2': 0.8399}]\n",
      "epoch 32: 100%|███| 1366/1366 [00:09<00:00, 140.45it/s, loss=3.82e+9, metrics={'r2': 0.8394}]\n",
      "epoch 33: 100%|███| 1366/1366 [00:09<00:00, 143.11it/s, loss=3.81e+9, metrics={'r2': 0.8398}]\n",
      "epoch 34: 100%|████| 1366/1366 [00:09<00:00, 144.47it/s, loss=3.8e+9, metrics={'r2': 0.8402}]\n",
      "epoch 35: 100%|███| 1366/1366 [00:09<00:00, 139.54it/s, loss=3.79e+9, metrics={'r2': 0.8404}]\n",
      "epoch 36: 100%|███| 1366/1366 [00:09<00:00, 143.11it/s, loss=3.77e+9, metrics={'r2': 0.8411}]\n",
      "epoch 37: 100%|███| 1366/1366 [00:09<00:00, 138.90it/s, loss=3.77e+9, metrics={'r2': 0.8413}]\n",
      "epoch 38: 100%|███| 1366/1366 [00:09<00:00, 142.50it/s, loss=3.79e+9, metrics={'r2': 0.8404}]\n",
      "epoch 39: 100%|███| 1366/1366 [00:09<00:00, 146.61it/s, loss=3.78e+9, metrics={'r2': 0.8409}]\n",
      "epoch 40: 100%|███| 1366/1366 [00:09<00:00, 137.68it/s, loss=3.76e+9, metrics={'r2': 0.8416}]\n",
      "epoch 41: 100%|███| 1366/1366 [00:09<00:00, 140.92it/s, loss=3.76e+9, metrics={'r2': 0.8419}]\n",
      "epoch 42: 100%|███| 1366/1366 [00:09<00:00, 138.55it/s, loss=3.77e+9, metrics={'r2': 0.8412}]\n",
      "epoch 43: 100%|███| 1366/1366 [00:09<00:00, 142.06it/s, loss=3.77e+9, metrics={'r2': 0.8416}]\n",
      "epoch 44: 100%|███| 1366/1366 [00:09<00:00, 142.45it/s, loss=3.74e+9, metrics={'r2': 0.8428}]\n",
      "epoch 45: 100%|███| 1366/1366 [00:09<00:00, 137.42it/s, loss=3.76e+9, metrics={'r2': 0.8419}]\n",
      "epoch 46: 100%|███| 1366/1366 [00:09<00:00, 137.59it/s, loss=3.72e+9, metrics={'r2': 0.8434}]\n",
      "epoch 47: 100%|███| 1366/1366 [00:09<00:00, 140.51it/s, loss=3.73e+9, metrics={'r2': 0.8432}]\n",
      "epoch 48: 100%|███| 1366/1366 [00:09<00:00, 139.84it/s, loss=3.71e+9, metrics={'r2': 0.8437}]\n",
      "epoch 49: 100%|███| 1366/1366 [00:09<00:00, 143.41it/s, loss=3.71e+9, metrics={'r2': 0.8439}]\n",
      "epoch 50: 100%|███| 1366/1366 [00:09<00:00, 140.00it/s, loss=3.72e+9, metrics={'r2': 0.8433}]\n",
      "epoch 51: 100%|███| 1366/1366 [00:09<00:00, 143.10it/s, loss=3.72e+9, metrics={'r2': 0.8435}]\n",
      "epoch 52: 100%|███| 1366/1366 [00:10<00:00, 136.49it/s, loss=3.72e+9, metrics={'r2': 0.8435}]\n",
      "epoch 53: 100%|███| 1366/1366 [00:09<00:00, 139.33it/s, loss=3.72e+9, metrics={'r2': 0.8436}]\n",
      "epoch 54: 100%|████| 1366/1366 [00:09<00:00, 139.87it/s, loss=3.71e+9, metrics={'r2': 0.844}]\n",
      "epoch 55: 100%|███| 1366/1366 [00:10<00:00, 136.13it/s, loss=3.72e+9, metrics={'r2': 0.8435}]\n",
      "epoch 56: 100%|███| 1366/1366 [00:09<00:00, 139.66it/s, loss=3.71e+9, metrics={'r2': 0.8441}]\n",
      "epoch 57: 100%|████| 1366/1366 [00:09<00:00, 138.09it/s, loss=3.71e+9, metrics={'r2': 0.844}]\n",
      "epoch 58: 100%|███| 1366/1366 [00:09<00:00, 139.04it/s, loss=3.69e+9, metrics={'r2': 0.8446}]\n",
      "epoch 59: 100%|███| 1366/1366 [00:09<00:00, 140.85it/s, loss=3.67e+9, metrics={'r2': 0.8453}]\n",
      "epoch 60: 100%|███| 1366/1366 [00:09<00:00, 144.34it/s, loss=3.67e+9, metrics={'r2': 0.8455}]\n",
      "epoch 61: 100%|███| 1366/1366 [00:10<00:00, 135.88it/s, loss=3.66e+9, metrics={'r2': 0.8458}]\n",
      "epoch 62: 100%|███| 1366/1366 [00:09<00:00, 141.66it/s, loss=3.67e+9, metrics={'r2': 0.8454}]\n",
      "epoch 63: 100%|███| 1366/1366 [00:10<00:00, 135.80it/s, loss=3.65e+9, metrics={'r2': 0.8462}]\n",
      "epoch 64: 100%|███| 1366/1366 [00:09<00:00, 139.74it/s, loss=3.67e+9, metrics={'r2': 0.8456}]\n",
      "epoch 65: 100%|███| 1366/1366 [00:09<00:00, 140.95it/s, loss=3.69e+9, metrics={'r2': 0.8447}]\n",
      "epoch 66: 100%|███| 1366/1366 [00:09<00:00, 145.07it/s, loss=3.66e+9, metrics={'r2': 0.8458}]\n",
      "epoch 67: 100%|███| 1366/1366 [00:10<00:00, 136.42it/s, loss=3.67e+9, metrics={'r2': 0.8455}]\n",
      "epoch 68: 100%|███| 1366/1366 [00:10<00:00, 135.07it/s, loss=3.66e+9, metrics={'r2': 0.8462}]\n",
      "epoch 69: 100%|███| 1366/1366 [00:10<00:00, 135.78it/s, loss=3.65e+9, metrics={'r2': 0.8463}]\n",
      "epoch 70: 100%|███| 1366/1366 [00:09<00:00, 139.82it/s, loss=3.67e+9, metrics={'r2': 0.8456}]\n",
      "epoch 71: 100%|███| 1366/1366 [00:10<00:00, 134.24it/s, loss=3.64e+9, metrics={'r2': 0.8469}]\n",
      "epoch 72: 100%|███| 1366/1366 [00:10<00:00, 135.27it/s, loss=3.65e+9, metrics={'r2': 0.8462}]\n",
      "epoch 73: 100%|███| 1366/1366 [00:10<00:00, 136.18it/s, loss=3.64e+9, metrics={'r2': 0.8469}]\n",
      "epoch 74: 100%|███| 1366/1366 [00:10<00:00, 134.72it/s, loss=3.65e+9, metrics={'r2': 0.8464}]\n",
      "epoch 75: 100%|███| 1366/1366 [00:09<00:00, 140.70it/s, loss=3.66e+9, metrics={'r2': 0.8462}]\n",
      "epoch 76: 100%|███| 1366/1366 [00:10<00:00, 136.09it/s, loss=3.62e+9, metrics={'r2': 0.8475}]\n",
      "epoch 77: 100%|████| 1366/1366 [00:10<00:00, 133.89it/s, loss=3.64e+9, metrics={'r2': 0.847}]\n",
      "epoch 78: 100%|███| 1366/1366 [00:10<00:00, 135.36it/s, loss=3.62e+9, metrics={'r2': 0.8479}]\n",
      "epoch 79: 100%|███| 1366/1366 [00:10<00:00, 132.36it/s, loss=3.64e+9, metrics={'r2': 0.8467}]\n",
      "epoch 80: 100%|███| 1366/1366 [00:09<00:00, 136.85it/s, loss=3.61e+9, metrics={'r2': 0.8481}]\n",
      "epoch 81: 100%|███| 1366/1366 [00:09<00:00, 138.53it/s, loss=3.61e+9, metrics={'r2': 0.8483}]\n",
      "epoch 82: 100%|███| 1366/1366 [00:10<00:00, 134.40it/s, loss=3.62e+9, metrics={'r2': 0.8478}]\n",
      "epoch 83: 100%|███| 1366/1366 [00:09<00:00, 139.76it/s, loss=3.62e+9, metrics={'r2': 0.8479}]\n",
      "epoch 84: 100%|████| 1366/1366 [00:10<00:00, 133.85it/s, loss=3.6e+9, metrics={'r2': 0.8485}]\n",
      "epoch 85: 100%|████| 1366/1366 [00:10<00:00, 135.72it/s, loss=3.59e+9, metrics={'r2': 0.849}]\n",
      "epoch 86: 100%|███| 1366/1366 [00:09<00:00, 137.75it/s, loss=3.62e+9, metrics={'r2': 0.8475}]\n",
      "epoch 87: 100%|███| 1366/1366 [00:09<00:00, 144.10it/s, loss=3.59e+9, metrics={'r2': 0.8491}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 88: 100%|████| 1366/1366 [00:08<00:00, 152.22it/s, loss=3.6e+9, metrics={'r2': 0.8487}]\n",
      "epoch 89: 100%|████| 1366/1366 [00:09<00:00, 146.54it/s, loss=3.6e+9, metrics={'r2': 0.8484}]\n",
      "epoch 90: 100%|███| 1366/1366 [00:08<00:00, 160.25it/s, loss=3.61e+9, metrics={'r2': 0.8482}]\n",
      "epoch 91: 100%|████| 1366/1366 [00:08<00:00, 160.75it/s, loss=3.61e+9, metrics={'r2': 0.848}]\n",
      "epoch 92: 100%|███| 1366/1366 [00:08<00:00, 158.24it/s, loss=3.57e+9, metrics={'r2': 0.8498}]\n",
      "epoch 93: 100%|████| 1366/1366 [00:08<00:00, 163.05it/s, loss=3.6e+9, metrics={'r2': 0.8487}]\n",
      "epoch 94: 100%|████| 1366/1366 [00:08<00:00, 159.00it/s, loss=3.6e+9, metrics={'r2': 0.8485}]\n",
      "epoch 95: 100%|███| 1366/1366 [00:08<00:00, 163.22it/s, loss=3.61e+9, metrics={'r2': 0.8481}]\n",
      "epoch 96: 100%|███| 1366/1366 [00:09<00:00, 146.00it/s, loss=3.58e+9, metrics={'r2': 0.8494}]\n",
      "epoch 97: 100%|███| 1366/1366 [00:09<00:00, 151.09it/s, loss=3.57e+9, metrics={'r2': 0.8497}]\n",
      "epoch 98: 100%|███| 1366/1366 [00:09<00:00, 144.79it/s, loss=3.58e+9, metrics={'r2': 0.8495}]\n",
      "epoch 99: 100%|███| 1366/1366 [00:09<00:00, 138.07it/s, loss=3.59e+9, metrics={'r2': 0.8489}]\n",
      "epoch 100: 100%|██| 1366/1366 [00:09<00:00, 146.09it/s, loss=3.58e+9, metrics={'r2': 0.8495}]\n"
     ]
    }
   ],
   "source": [
    "# Training Model with 100 Epochs with Batch Size 64\n",
    "trainer.fit(X_tab = X_tab, \n",
    "            target = df_train['resale_price'].values, \n",
    "            n_epochs = 100, \n",
    "            batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V46s-MdM0y5c"
   },
   "source": [
    ">Report the test RMSE and the test R2 value that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████████████████████████████████████| 1128/1128 [00:02<00:00, 499.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Scaled Test Data\n",
    "X_test = tab_preprocessor.transform(df_test)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = trainer.predict(X_tab = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103143.89, 135814.58, 273692.06, ..., 632185.75, 582168.06,\n",
       "       600626.3 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KAhAgvMC07g6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.6162854537452702\n",
      "Root Mean Squared Error (RMSE): 104798.4517345718\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = df_test['resale_price']\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 value obtained is 0.6162854537452702 and RMSE value is 104798.4517345718"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
